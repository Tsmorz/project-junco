{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flappy Bird Junco Sim\n",
    "2D flight sim for EECE5500 Mobile Robotics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### Import libraries ###############################\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from numpy import matlib\n",
    "\n",
    "import gym\n",
    "# import control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Drone():\n",
    "    m = 3.2\n",
    "    Iyy = 1/12*m*0.8**2\n",
    "\n",
    "    S = 0.25\n",
    "    c = 0.13\n",
    "\n",
    "    Cl_0 = 0.5\n",
    "    Cl_alpha = 0.17\n",
    "\n",
    "    Cd_0 = 0.02\n",
    "    K = 0.01\n",
    "\n",
    "    Cm_0 = -0.05*0\n",
    "    Cm_alpha = 0.4\n",
    "    Cm_alpha_dot = -0.1*0\n",
    "    Cm_delta_e = 0.5\n",
    "\n",
    "    g = 9.81\n",
    "\n",
    "    def __init__(self):\n",
    "        self.x_thres = 1000\n",
    "        self.z_thresHigh = 500\n",
    "        self.z_thresLow = 0\n",
    "        self.v_thres = 50\n",
    "        self.theta_thres = np.pi/6\n",
    "        self.theta_dot_thres = np.pi\n",
    "        self.gamma_thres = np.pi/6\n",
    "        self.alpha_dot_stale = 0\n",
    "\n",
    "        self.limits = np.array([\n",
    "            self.x_thres,\n",
    "            self.z_thresHigh,\n",
    "            self.z_thresLow,\n",
    "            self.v_thres,\n",
    "            self.theta_thres,\n",
    "            self.theta_dot_thres,\n",
    "            self.gamma_thres\n",
    "        ])\n",
    "\n",
    "        self.state = None\n",
    "        self.prev_action = None\n",
    "        self.steps_beyond_terminated = None\n",
    "\n",
    "        self.time = 0.\n",
    "        self.dt = 0.01\n",
    "\n",
    "      \n",
    "    def step(self, action):\n",
    "        err_msg = f\"{action!r} ({type(action)}) invalid\"\n",
    "        assert self.state is not None, \"Call reset before using step method.\"\n",
    "        \n",
    "        self.time += self.dt\n",
    "\n",
    "        #Extra states\n",
    "        rho = np.random.normal(1.225,0.01)\n",
    "        alpha = self.state[3] - self.state[4]\n",
    "        self.q = 0.5*rho*self.state[2]**2\n",
    "        \n",
    "        #Control inputs\n",
    "        thrust, delta_e = action\n",
    "\n",
    "        # Forces\n",
    "        Cl = self.Cl_0 + self.Cl_alpha*alpha\n",
    "        Cd = self.Cd_0 + self.K*Cl**2\n",
    "        Cm = self.Cm_0 + self.Cm_alpha*alpha + self.Cm_alpha_dot*self.alpha_dot_stale + self.Cm_delta_e*delta_e\n",
    "        # print(self.Cm_0, self.Cm_alpha*alpha, self.Cm_alpha_dot*self.alpha_dot_stale, self.Cm_delta_e*delta_e)\n",
    "        L = self.q*self.S*Cl\n",
    "        D = self.q*self.S*Cd\n",
    "        M = self.q*self.S*Cm\n",
    "        x, z, v, theta, theta_dot, gamma = self.state\n",
    "\n",
    "        #derivatives\n",
    "        x_dot = v*np.cos(gamma)\n",
    "        z_dot = v*np.sin(gamma)\n",
    "        v_dot = (-D - self.m*self.g*np.sin(gamma) + thrust*np.cos(alpha)) / self.m\n",
    "        #theta_dot = theta_dot\n",
    "        theta_ddot = M / self.Iyy\n",
    "        gamma_dot = (L - self.m*self.g*np.cos(gamma) -thrust*np.sin(alpha)) / (self.m*v)\n",
    "\n",
    "        #No algebraic loops in my flight code \n",
    "        self.alpha_dot_stale = theta_dot - gamma_dot\n",
    "\n",
    "        # integrate\n",
    "        x += x_dot*self.dt\n",
    "        z += z_dot*self.dt\n",
    "        v += v_dot*self.dt\n",
    "        theta += theta_dot*self.dt #Removed second order terms.  We don't do that here (Also needs to be 1/2dt^2 f\"(t))\n",
    "        theta_dot += theta_ddot * self.dt\n",
    "        gamma += gamma_dot*self.dt\n",
    "\n",
    "        state = np.array([x,z,v,theta,theta_dot,gamma])\n",
    "        action = np.array([thrust,delta_e])\n",
    "\n",
    "        self.state = (list(np.reshape(state,(6,))))\n",
    "\n",
    "        terminated = bool(\n",
    "            x < -self.x_thres\n",
    "            or x > self.x_thres\n",
    "            or z > self.z_thresHigh\n",
    "            or z < self.z_thresLow\n",
    "            or v < -self.v_thres\n",
    "            or v > self.v_thres\n",
    "            or theta < -self.theta_thres\n",
    "            or theta > self.theta_thres\n",
    "            or theta_dot < -self.theta_dot_thres\n",
    "            or theta_dot > self.theta_dot_thres\n",
    "            or gamma < -self.gamma_thres\n",
    "            or gamma > self.gamma_thres\n",
    "        )\n",
    "\n",
    "        if not terminated:\n",
    "            reward = 1.0\n",
    "        elif self.steps_beyond_terminated is None:\n",
    "            self.steps_beyond_terminated = 0\n",
    "            reward = 0.0\n",
    "        else:\n",
    "            if self.steps_beyond_terminated == 0:\n",
    "                print(self.state)\n",
    "                gym.logger.warn(\n",
    "                    \"You are calling 'step()' even though this \"\n",
    "                    \"environment has already returned terminated = True. You \"\n",
    "                    \"should always call 'reset()' once you receive 'terminated = \"\n",
    "                    \"True' -- any further steps are undefined behavior.\"\n",
    "                )\n",
    "            self.steps_beyond_terminated += 1\n",
    "            reward = 0.0\n",
    "\n",
    "        return state, reward, terminated, False\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = np.array([0,0,20,0,0,0])\n",
    "        self.steps_beyond_terminated = None\n",
    "        self.time = 0\n",
    "\n",
    "        return self.state\n",
    "\n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Drone()\n",
    "state = env.reset()\n",
    "action = np.array([1.5,0.000001])\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "trajx = []\n",
    "trajz = []\n",
    "trajtheta = []\n",
    "trajgamma = []\n",
    "trajv = []\n",
    "\n",
    "for t in range(1, 1000):\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    x = state[0]\n",
    "    z = state[1]\n",
    "    v = state[2]\n",
    "    theta = state[3]\n",
    "    theta_dot = state[4]\n",
    "    gamma = state[5]\n",
    "    trajx.append(x)\n",
    "    trajz.append(z)\n",
    "    trajtheta.append(theta)\n",
    "    trajgamma.append(gamma)\n",
    "    trajv.append(v)\n",
    "\n",
    "axs[0, 0].plot(trajx, trajz)\n",
    "axs[0, 0].set_ylabel(\"Height (m)\")\n",
    "axs[0, 1].plot(trajx, trajtheta)\n",
    "axs[0, 1].set_ylabel(\"Theta (rad)\")\n",
    "axs[1, 0].plot(trajx, trajgamma)\n",
    "axs[1, 0].set_ylabel(\"Gamma (rad)\")\n",
    "axs[1, 1].plot(trajx, trajv)\n",
    "axs[1, 1].set_ylabel(\"Velocity (m/s)\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.6600e+00  1.0019e+02  2.5000e+01  3.0000e-02 -3.1700e+00  5.0000e-02] 0.0 True\n"
     ]
    }
   ],
   "source": [
    "#################################### Testing ###################################\n",
    "\n",
    "env = Drone()\n",
    "state = env.reset()\n",
    "action = np.array([1.5,1])\n",
    "\n",
    "%matplotlib qt\n",
    "fig, ax = plt.subplots(1,figsize=(10,5))\n",
    "traj = []\n",
    "\n",
    "for t in range(1, 1000):\n",
    "    \n",
    "    state, reward, done, _ = env.step(action)\n",
    "    x = state[0]\n",
    "    z = -state[1]\n",
    "    v = state[2]\n",
    "    theta = -state[3]\n",
    "    theta_dot = -state[4]\n",
    "    gamma = state[5]\n",
    "    traj.append((x,z))\n",
    "\n",
    "    action = np.array([0,0])\n",
    "        \n",
    "    if v<25:\n",
    "        action[0] = 200\n",
    "    else:\n",
    "        action[0] = 0\n",
    "        \n",
    "    l = 0.8\n",
    "    plt.plot([x,x+0.25*l*np.cos(theta)],[z,z+0.25*l*np.sin(theta)],'k-')\n",
    "    plt.plot([x,x-0.75*l*np.cos(theta)],[z,z-0.75*l*np.sin(theta)],'k-')\n",
    "    plt.xlim(x-20,x+80)\n",
    "    plt.ylim(z-25,z+25)\n",
    "\n",
    "    beam = 50\n",
    "    angle = 60*np.pi/180\n",
    "    plt.plot([x,x+beam*np.cos(theta+angle/2)],[z,z+beam*np.sin(theta+angle/2)],'k--')\n",
    "    plt.plot([x,x+beam*np.cos(theta-angle/2)],[z,z+beam*np.sin(theta-angle/2)],'k--')\n",
    "    xs = x+beam*np.cos(theta+np.linspace(-angle/2,angle/2,10))\n",
    "    zs = z+beam*np.sin(theta+np.linspace(-angle/2,angle/2,10))\n",
    "    plt.plot(xs,zs,'k.',markersize=1)\n",
    "\n",
    "    x,z = zip(*traj)\n",
    "    plt.plot(x,z,'b-',markersize=1)\n",
    "    \n",
    "    plt.show()\n",
    "    plt.pause(env.dt)\n",
    "\n",
    "    \n",
    "    if done:\n",
    "        break\n",
    "    else:\n",
    "        ax.clear()\n",
    "print(np.around(state,2), reward, done)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "junco-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9dd5eae11c0988cf60f510d248b605991d314fcf26b650ae66263c6e0f74d826"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
